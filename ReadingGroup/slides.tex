\documentclass{beamer}
%\documentclass[handout,t]{beamer}

\batchmode
% \usepackage{pgfpages}
% \pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=5mm]

\usepackage{amsmath,amssymb,amsfonts,enumerate,epsfig,bbm,calc,color,ifthen,capt-of}

\usetheme{Berlin}
\usecolortheme{mit}
\usefonttheme[onlymath]{serif}

\title{Task-agnostic Continual Learning with Hybrid Probabilistic Models}
\author[Polina Kirichenko \and Mehrdad Farajtabar]{
  Polina Kirichenko \inst{1} \and Mehrdad Farajtabar \inst{2} \and Dushyant Rao \inst{2} \\
  Balaji Lakshminarayanan \inst{3} \and Nir Levine \inst{2} \and Ang Li \inst{2} \\
  Huiyi Hu \inst{2} \and Andrew Gordon Wilson \inst{1} \and Razvan Pascanu \inst{2}
}

\institute[NYU \and DeepMind \and Google Brain]{
  \inst{1} New York University \and
  \inst{2} DeepMind \and
  \inst{3} Google Brain
}
\date{\today}
% \pgfdeclareimage[height=0.5cm]{mit-logo}{mit-logo.pdf}
% \logo{\pgfuseimage{mit-logo}\hspace*{0.3cm}}

% \AtBeginSection[]
% {
%   \begin{frame}<beamer>
%     \frametitle{Outline}
%     \tableofcontents[currentsection]
%   \end{frame}
% }
\beamerdefaultoverlayspecification{<+->}
% -----------------------------------------------------------------------------
\begin{document}
% -----------------------------------------------------------------------------

\frame{\titlepage}

\section[Outline]{}
\begin{frame}{Outline}
  \tableofcontents
\end{frame}

% -----------------------------------------------------------------------------
\section{Introduction}
% \subsection{Smoot's Ear: The Measure of Humanity}
\begin{frame}{Existing Approaches}
  \begin{itemize}
    \item<1-> re-sample the data or design specific loss functions that better facilitate learning with imbalanced data
    \item<1-> enhance recognition performance of the tail classes by transferring knowledge from the head classes
  \end{itemize}
  
  % \begin{block}{Title of}
  %   hi
  % \end{block}
\end{frame}

\begin{frame}{Our Contribution}
  \begin{itemize}
    \item <1-> Hybrid Continual Learning (HCL) - a normalizing flow-based approach.
    \item Generative replay and a novel functional regularization are employed to alleviate forgetting. The functional regularization is shown to be better than generative replay.
    \item <1-> HCL achieves strong performance on \emph{split MNIST}, \emph{split CIFAR}, \emph{SVHN-MNIST} and \emph{MNIST-SVHN} datasets.
    \item <1-> HCL can detect task boundaries and identify new as well as recurring tasks.
  \end{itemize}
\end{frame}

% -----------------------------------------------------------------------------
\section{Background and Notation}
\begin{frame}{Continual Learning (CL)}
  \begin{itemize}
    \item <1-> A CL model $g_\theta : \mathcal{X} \rightarrow \mathcal{Y}$.
    \item <1-> A sequence of $\tau$ supervised tasks: $T_{t_1}, \ T_{t_2}, \dots, T_{t_\tau}$. $\tau$ is not known in advance.
    \item <1-> Each task $T_i = \{ (x_j^i, y_j^i) \}_{j = 1}^{N_i}$, where $x_j^i \in \mathcal{X}^i$ and $y_j^i \in \mathcal{Y}^i$.
    \item <1-> The corresponding data distribution of task $T_i$ is $p_i(x, y)$.
    \item <1-> \textbf{Constraint}: While training on a task $T_i$ the model cannot access to the data from previous $T_1, \dots, T_{i-1}$ or future tasks $T_{i+1}, \dots, T_{\tau}$.
    \item <1-> \textbf{Objective}: Minimize $\sum_{i = 1}^M \mathbb{E}_{x, y \sim p_i(\cdot, \cdot)}l(g_\theta(x), y)$ for some risk function $l(\cdot, \cdot)$ and generalize well on all tasks after training.
  \end{itemize} 
\end{frame}

% -----------------------------------------------------------------------------
\section{HCL}
\begin{frame}{Modeling the Data Distribution}
  \begin{itemize}
    \item <1-> $p_t(x, y)$: the joint distribution of the data $x$ and the class label $y$ conditioned on a task $t$.
    \[
      p_t(x, y) \approx \hat{p}(x, y | t) = \hat{p}_X(x | y, t) \hat{p}(y | t)
    \]
    \item <1-> $\hat{p}_X(x | y, t)$ is modeled by a normalizing flow $f_\theta$ with a base distribution $\hat{p}_Z = \mathcal{N}(\mu_{y, t}, I)$.
    \[
      \hat{p}_X(x | y, t) = f_\theta^{-1}\left( \mathcal{N}(\mu_{y, t}, I) \right)
    \]
    \item <1-> $\mu_{y, t}$ is the mean of the latent distribution corresponding to the class $y$ and task $t$.
    \item <1-> $\hat{p}(y | t)$ is assumed to be a uniform distribution over the classes for each task: $\hat{p}(y | t) = 1/K$.
  \end{itemize}
\end{frame}

\begin{frame}{Task Identification}
  \begin{itemize}
    \item <1-> log-likelihood
    \[
      S_1(B, t) = \sum_{(x_j, y_j) \in B} \hat{p}_X(x_j | y_j, t)
    \]
    \item <1-> log-likelihood of the latent variable 
    \[
      S_2(B, t) = \sum_{(x_j, y_j) \in B} \hat{p}_Z(f_\theta(x_j) | y_j, t)
    \]
    \item <1-> log-determinant of the Jacobian
    \[
      S_3(B, t) = S_1(B, t) - S_2(B, t)
    \]
  \end{itemize}
\end{frame}

\begin{frame}{Generative Replay (HCL-GR)}
  \begin{itemize}
    \item <1-> Store a single snapshot of the HCL model $\hat{p}_X^{(k)}(x | y, t)$ with weights $\theta^{(k)}$.
    \item <1-> Generate and replay data from old tasks using the snapshot: $x_{GR} \sim \hat{p}_X^{(k)}(x | y, t)$, where $y \sim U\{1, \dots, K\}$ and $t \sim U\{t_1, \dots, t_k\}$.
    \item <1-> Maximize the likelihood $\mathcal{L}_{GR} = \log \hat{p}_X (x_{GR} | y, t)$ under the current model $\hat{p}_X(\cdot)$.
    \item <1-> The resulting loss in generative replay training is $\mathcal{L}_{ll} + \mathcal{L}_{GR}$, where $\mathcal{L}_{ll}$ is the log-likelihood of the data on the current task.
    \item <1-> Update the snapshot with new weights $\theta^{(k+1)}$ after detecting the task change $T_{t_{k+1}} \rightarrow T_{t_{k+2}}$. 
  \end{itemize}
\end{frame}

\begin{frame}{Functional Regularization (HCL-FR)}
  Enforce the flow to map samples from previous tasks to the same latent representations as a snapshot model.

  \begin{itemize}
    \item <1-> Store a single snapshot of the model $\hat{p}_X^{(k)}(\cdot)$ and produce samples $x_{FR} \sim \hat{p}_X^{(k)}(x | y, t)$ for $y \sim U\{1, \dots, K\}$, $t \sim U\{t_1, \dots, t_k\}$.
    \item <1-> $\mathcal{L}_{FR} = \left\| f_\theta(x_{FR}) - f_{\theta^{(k)}}(x_{FR}) \right\|^2$, where $f_\theta$ is the current flow mapping and $f_{\theta^{(k)}}$ is the snapshot model.
    \item <1-> The resulting loss in functional regularization is $\mathcal{L}_{ll} + \alpha \mathcal{L}_{FR}$.
  \end{itemize}
\end{frame}

\begin{frame}{Theoretical Analysis}
  
\end{frame}

% -----------------------------------------------------------------------------
\section{Experiments}
\begin{frame}{Compared Methods}
  \begin{itemize}
    \item <1-> Adam: Train the model with Adam optimizer without any extra steps for preventing forgetting.
    \item <1-> Multi-Task Learning (MTL): When training on $T_{t_i}$, it has access to all previous tasks $T_{t_1}, \dots, T_{t_{i-1}}$.
    \item <1-> Experience Replay (ER):
    \item <1-> CURL:
  \end{itemize}
\end{frame}

\begin{frame}{Datasets}
  \begin{itemize}
    \item <1-> Split MNIST: Split the dataset into 5 binary classification tasks. 
    \item <1-> MNIST-SVHN and SVHN-MNIST:
    \item <1-> Split CIFAR:
  \end{itemize}
\end{frame}

\begin{frame}{Experiment Results}
  
\end{frame}

\begin{frame}{Experiment Results on Split CIFAR}
  
\end{frame}

% -----------------------------------------------------------------------------
\section{Discussion}
\begin{frame}
  
\end{frame}

% -----------------------------------------------------------------------------
\end{document}
